<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Midterm Exam: Advanced Machine Learning</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
        }
        h2 {
            border-bottom: 2px solid #3498db;
            padding-bottom: 5px;
        }
        h3 {
            margin-top: 20px;
        }
        p, li {
            color: #333;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: center;
        }
        th {
            background-color: #f2f2f2;
        }
        .instructions {
            background-color: #ecf0f1;
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
        }
    </style>
</head>
<body>
    <h1>Midterm Exam: Advanced Machine Learning</h1>
    <p><strong>Date:</strong> April 02, 2025<br>
       <strong>Duration:</strong> 2 hours</p>

    <div class="instructions">
        <h3>Instructions:</h3>
        <ul>
            <li>Answer all questions.</li>
            <li>Show your work for partial credit where applicable.</li>
        </ul>
    </div>

    <div class="section">
        <h2>Section 1: Classification Metrics</h2>

        <h3>1. Short Answer</h3>
        <ol type="a">
            <li>Define precision, recall, and F1-score in the context of binary classification.</li>
            <li>Explain a scenario where precision might be more important than recall, and vice versa. Provide a concrete example for each.</li>
            <li>Why might the F1-score be preferred over accuracy as a metric in imbalanced datasets?</li>
        </ol>

        <h3>2. Problem Solving</h3>
        <p>Consider a binary classifier with the following confusion matrix:</p>
        <ul>
            <li>True Positives (TP) = 50</li>
            <li>False Positives (FP) = 20</li>
            <li>True Negatives (TN) = 900</li>
            <li>False Negatives (FN) = 30</li>
        </ul>
        <ol type="a">
            <li>Compute the precision, recall, and F1-score.</li>
            <li>If the cost of a false positive is 5 times higher than the cost of a false negative, design a custom metric to evaluate this classifier and compute its value.</li>
            <li>How would you adjust the decision threshold to prioritize recall over precision? Explain qualitatively.</li>
        </ol>
    </div>

    <div class="section">
        <h2>More on Classification Metrics</h2>
        <ol type="a">
            <li>Describe the beta distribution and explain why it is suitable for modeling the accuracy of a machine learning classifier. Describe its parameters.</li>
            <li>How do the shape parameters (α and β) of the beta distribution relate to the number of correct and incorrect predictions?</li>

        </ol>

        <h3>3. Practical Application</h3>
        <p>Suppose you have a classifier that was tested on 10 samples, with 8 correct predictions and 2 incorrect predictions.</p>
        <ol type="a">
            <li>Model the classifier’s accuracy using a beta distribution. Specify the parameters α and β, and write the corresponding probability density function.</li>
            <li>Compute the expected value (mean) and variance of this beta distribution. Interpret what these values tell you about the classifier’s performance.</li>
            <li>Using this beta distribution, calculate the probability that the classifier’s true accuracy is greater than 0.85. (You may leave your answer in terms of an integral or use a statistical table if provided.)</li>
            <li>If you were to collect 5 more samples and the classifier achieved 4 correct predictions, how would the beta distribution parameters update? What does this suggest about the stability of the classifier’s accuracy?</li>
            <li>I have tested a classifier over 10 different customers, and i have measured an accuracy of 0.7. Now I have a new customer. How should I think about testing the classifier on the new customer? How many examples are "enough"? </li>
            <li>Somebody gives you 100 000 data points. You have to train and test a binary classifier. How do you decide your train/test split </li>

        </ol>
        <h3>Fairness</h3>
        <p>Suppose you have a classifier that determines if people are likely to repay a loan. The classifiers outputs a score for each person.
            Given a classification, you have TP, TN, FP, FN. What are some criteria you can define to measure if the classifier is fair across groups of interest?
            How would you approach this problem? What are some potential challenges?
        </p>
    </div>

    <div class="section">
        <h2>Section 3: Clustering Metrics</h2>

        <h3>5. Definitions and Interpretation</h3>
        <ol type="a">
            <li>Define purity, homogeneity, and completeness as clustering evaluation metrics.</li>
            <li>Explain one key limitation of purity as a metric and how homogeneity or completeness might address this limitation.</li>
        </ol>

        <h3>6. Problem Solving</h3>
        <p>Consider a clustering result with 3 clusters and the following contingency table comparing cluster assignments to true labels:</p>
        <table>
            <tr>
                <th>Cluster</th>
                <th>Class A</th>
                <th>Class B</th>
                <th>Class C</th>
            </tr>
            <tr>
                <td>C1</td>
                <td>40</td>
                <td>10</td>
                <td>5</td>
            </tr>
            <tr>
                <td>C2</td>
                <td>5</td>
                <td>30</td>
                <td>5</td>
            </tr>
            <tr>
                <td>C3</td>
                <td>10</td>
                <td>5</td>
                <td>40</td>
            </tr>
        </table>
        <ol type="a">
            <li>Compute the purity of the clustering. Show your work.</li>
            <li>Calculate the homogeneity of the clustering using entropy-based measures. (Hint: Use base-2 logarithm for entropy calculations.)</li>
            <li>Calculate the completeness of the clustering.</li>
            <li>Based on your results, discuss whether this clustering is more “pure” or more “homogeneous.” What might this imply about the clustering algorithm’s performance? (Extra credit question)</li>
        </ol>
    </div>

    <p><strong>End of Exam</strong></p>
</body>
</html>