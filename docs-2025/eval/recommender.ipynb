{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabio.casati/.venvs/3new/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader, SVD, KNNBasic, NormalPredictor\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate, train_test_split \u001b[38;5;28;01mas\u001b[39;00m surprise_train_test_split\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccuracy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rmse \u001b[38;5;28;01mas\u001b[39;00m surprise_rmse, mae \u001b[38;5;28;01mas\u001b[39;00m surprise_mae\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Recommender System Evaluation Script\n",
    "\n",
    "This script downloads datasets, implements basic recommender systems,\n",
    "evaluates them using various metrics, and visualizes the results.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic, NormalPredictor\n",
    "from surprise.model_selection import cross_validate, train_test_split as surprise_train_test_split\n",
    "from surprise.accuracy import rmse as surprise_rmse, mae as surprise_mae\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset Loading Functions\n",
    "# =============================================================================\n",
    "\n",
    "def download_file(url, save_path=None):\n",
    "    \"\"\"\n",
    "    Download a file from a URL\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    url : str\n",
    "        URL to download from\n",
    "    save_path : str, optional\n",
    "        Path to save the file. If None, file is returned as bytes\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bytes or bool\n",
    "        File content as bytes if save_path is None, else True if successful\n",
    "    \"\"\"\n",
    "    print(f\"Downloading from {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error downloading file: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"File saved to {save_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        return response.content\n",
    "\n",
    "def download_movielens(size='100k', data_dir='data'):\n",
    "    \"\"\"\n",
    "    Download MovieLens dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    size : str\n",
    "        Size of the dataset ('100k', '1m', '10m', '20m', or 'latest-small')\n",
    "    data_dir : str\n",
    "        Directory to save the dataset\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing ratings data\n",
    "    \"\"\"\n",
    "    urls = {\n",
    "        '100k': 'https://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
    "        '1m': 'https://files.grouplens.org/datasets/movielens/ml-1m.zip',\n",
    "        '10m': 'https://files.grouplens.org/datasets/movielens/ml-10m.zip',\n",
    "        '20m': 'https://files.grouplens.org/datasets/movielens/ml-20m.zip',\n",
    "        'latest-small': 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "    }\n",
    "    \n",
    "    if size not in urls:\n",
    "        raise ValueError(f\"Invalid size. Choose from: {', '.join(urls.keys())}\")\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # Create a subdirectory for this specific dataset\n",
    "    dataset_dir = os.path.join(data_dir, f'ml-{size}')\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.makedirs(dataset_dir)\n",
    "    \n",
    "    zip_path = os.path.join(data_dir, f'ml-{size}.zip')\n",
    "    \n",
    "    # Download if not already exists\n",
    "    if not os.path.exists(zip_path):\n",
    "        content = download_file(urls[size], zip_path)\n",
    "        if not content:\n",
    "            return None\n",
    "    \n",
    "    # Extract ZIP file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "    \n",
    "    # Load ratings data\n",
    "    if size == '100k':\n",
    "        ratings_path = os.path.join(data_dir, 'ml-100k', 'u.data')\n",
    "        ratings = pd.read_csv(ratings_path, sep='\\t', \n",
    "                             names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "        \n",
    "        # Load movie data\n",
    "        movies_path = os.path.join(data_dir, 'ml-100k', 'u.item')\n",
    "        movies = pd.read_csv(movies_path, sep='|', encoding='latin-1',\n",
    "                           names=['item_id', 'title', 'release_date', 'video_release_date',\n",
    "                                 'IMDb_URL'] + [f'genre_{i}' for i in range(19)])\n",
    "        \n",
    "        # Extract genre information\n",
    "        genre_cols = [col for col in movies.columns if 'genre_' in col]\n",
    "        movies['genres'] = movies[genre_cols].apply(lambda x: '/'.join([g for i, g in \n",
    "                                                                       zip(x, ['Action', 'Adventure', 'Animation',\n",
    "                                                                             'Children\\'s', 'Comedy', 'Crime',\n",
    "                                                                             'Documentary', 'Drama', 'Fantasy',\n",
    "                                                                             'Film-Noir', 'Horror', 'Musical',\n",
    "                                                                             'Mystery', 'Romance', 'Sci-Fi',\n",
    "                                                                             'Thriller', 'War', 'Western', 'Unknown'])\n",
    "                                                                       if i == 1]), axis=1)\n",
    "    else:\n",
    "        # For other sizes, load in appropriate format\n",
    "        if size in ['1m', '10m', '20m']:\n",
    "            separator = '::'\n",
    "            header = None\n",
    "            names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "        else:  # latest-small\n",
    "            separator = ','\n",
    "            header = 0\n",
    "            names = None\n",
    "        \n",
    "        ratings_path = os.path.join(data_dir, f'ml-{size}', 'ratings.dat' if size in ['1m', '10m'] else 'ratings.csv')\n",
    "        ratings = pd.read_csv(ratings_path, sep=separator, header=header, names=names)\n",
    "        \n",
    "        # Load movie data\n",
    "        movies_path = os.path.join(data_dir, f'ml-{size}', 'movies.dat' if size in ['1m', '10m'] else 'movies.csv')\n",
    "        if size in ['1m', '10m']:\n",
    "            movies = pd.read_csv(movies_path, sep=separator, header=header, \n",
    "                               names=['item_id', 'title', 'genres'], encoding='latin-1')\n",
    "        else:\n",
    "            movies = pd.read_csv(movies_path, encoding='latin-1')\n",
    "    \n",
    "    print(f\"Loaded MovieLens {size} dataset\")\n",
    "    print(f\"Ratings: {len(ratings)} | Users: {len(ratings['user_id'].unique())} | Items: {len(ratings['item_id'].unique())}\")\n",
    "    \n",
    "    return ratings, movies\n",
    "\n",
    "def download_lastfm(data_dir='data'):\n",
    "    \"\"\"\n",
    "    Download Last.fm dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : str\n",
    "        Directory to save the dataset\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing user-artist play counts\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    dataset_dir = os.path.join(data_dir, 'lastfm-360k')\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.makedirs(dataset_dir)\n",
    "    \n",
    "    # Last.fm 360K URL\n",
    "    url = 'http://mtg.upf.edu/static/datasets/last.fm/lastfm-360K.tar.gz'\n",
    "    \n",
    "    # Check if we already have the data\n",
    "    user_artists_path = os.path.join(dataset_dir, 'usersha1-artmbid-artname-plays.tsv')\n",
    "    if os.path.exists(user_artists_path):\n",
    "        print(\"Last.fm dataset already exists, loading...\")\n",
    "    else:\n",
    "        # This is a complex download and extraction process\n",
    "        # For simplicity, we'll just notify the user to download manually\n",
    "        print(\"The Last.fm dataset is large and complex to extract automatically.\")\n",
    "        print(f\"Please download from {url} and extract to {dataset_dir}\")\n",
    "        print(\"Expected file structure: usersha1-artmbid-artname-plays.tsv\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load user-artist data\n",
    "    try:\n",
    "        user_artists = pd.read_csv(user_artists_path, sep='\\t', \n",
    "                                  names=['user_id', 'artist_id', 'artist_name', 'plays'])\n",
    "        \n",
    "        # Clean up data\n",
    "        user_artists = user_artists.dropna(subset=['user_id', 'artist_name', 'plays'])\n",
    "        \n",
    "        # For artists without IDs, use name as ID\n",
    "        user_artists['artist_id'] = user_artists['artist_id'].fillna(user_artists['artist_name'])\n",
    "        \n",
    "        print(f\"Loaded Last.fm dataset\")\n",
    "        print(f\"Records: {len(user_artists)} | Users: {len(user_artists['user_id'].unique())} | Artists: {len(user_artists['artist_id'].unique())}\")\n",
    "        \n",
    "        # Last.fm doesn't have separate metadata, but we can create an artists dataframe\n",
    "        artists = user_artists[['artist_id', 'artist_name']].drop_duplicates()\n",
    "        \n",
    "        return user_artists, artists\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Last.fm dataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def download_amazon_reviews(category='Digital_Music', data_dir='data'):\n",
    "    \"\"\"\n",
    "    Download Amazon reviews dataset for a specific category\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    category : str\n",
    "        Product category ('Digital_Music', 'Books', 'Movies_and_TV', etc.)\n",
    "    data_dir : str\n",
    "        Directory to save the dataset\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing ratings data\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    dataset_dir = os.path.join(data_dir, f'amazon-{category.lower()}')\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.makedirs(dataset_dir)\n",
    "    \n",
    "    # Amazon reviews URL - we'll use the 5-core datasets which are smaller\n",
    "    url = f'https://jmcauley.ucsd.edu/data/amazon/subsets/{category}_5.json.gz'\n",
    "    \n",
    "    # Check if we already have the data\n",
    "    json_path = os.path.join(dataset_dir, f'{category}_5.json.gz')\n",
    "    if os.path.exists(json_path):\n",
    "        print(f\"Amazon {category} dataset already exists, loading...\")\n",
    "    else:\n",
    "        # For simplicity, we'll just notify the user to download manually\n",
    "        # These files can be large and complex to process\n",
    "        print(f\"The Amazon {category} dataset needs to be downloaded manually.\")\n",
    "        print(f\"Please download from {url} and save to {json_path}\")\n",
    "        print(\"Then use the pandas read_json function with lines=True and compression='gzip'\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load reviews data\n",
    "    try:\n",
    "        # This is a simplification - in reality, each line is a separate JSON object\n",
    "        reviews = pd.read_json(json_path, lines=True, compression='gzip')\n",
    "        \n",
    "        # Rename columns to match our standard format\n",
    "        reviews = reviews.rename(columns={\n",
    "            'reviewerID': 'user_id',\n",
    "            'asin': 'item_id',\n",
    "            'overall': 'rating',\n",
    "            'unixReviewTime': 'timestamp'\n",
    "        })\n",
    "        \n",
    "        # Extract needed columns\n",
    "        reviews = reviews[['user_id', 'item_id', 'rating', 'timestamp']]\n",
    "        \n",
    "        print(f\"Loaded Amazon {category} dataset\")\n",
    "        print(f\"Reviews: {len(reviews)} | Users: {len(reviews['user_id'].unique())} | Items: {len(reviews['item_id'].unique())}\")\n",
    "        \n",
    "        # Amazon datasets don't have separate metadata files in this format\n",
    "        # For simplicity, we'll return None for items\n",
    "        return reviews, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Amazon {category} dataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def prepare_dataset(ratings, test_size=0.2, implicit=False, threshold=None):\n",
    "    \"\"\"\n",
    "    Prepare dataset for training and testing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ratings : pandas.DataFrame\n",
    "        DataFrame containing ratings data\n",
    "    test_size : float\n",
    "        Proportion of data to use for testing\n",
    "    implicit : bool\n",
    "        Whether to convert to implicit feedback\n",
    "    threshold : float, optional\n",
    "        Threshold for implicit conversion (ratings above this are positive)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing train and test data in different formats\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    ratings_df = ratings.copy()\n",
    "    \n",
    "    # If implicit feedback is requested, convert ratings to binary\n",
    "    if implicit:\n",
    "        if threshold is None:\n",
    "            # If no threshold provided, use the median rating\n",
    "            threshold = ratings_df['rating'].median()\n",
    "        \n",
    "        print(f\"Converting to implicit feedback (threshold = {threshold})\")\n",
    "        ratings_df['rating'] = (ratings_df['rating'] >= threshold).astype(float)\n",
    "    \n",
    "    # Split into train and test sets (stratify by user to ensure all users have both train and test items)\n",
    "    user_encoder = LabelEncoder()\n",
    "    ratings_df['user_idx'] = user_encoder.fit_transform(ratings_df['user_id'])\n",
    "    \n",
    "    try:\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, test_size=test_size, stratify=ratings_df['user_idx'], random_state=42\n",
    "        )\n",
    "    except ValueError:\n",
    "        # If stratification fails (usually with very unbalanced data), try without stratification\n",
    "        print(\"Stratified split failed, falling back to random split\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            ratings_df, test_size=test_size, random_state=42\n",
    "        )\n",
    "    \n",
    "    # Create user and item encoders\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "    \n",
    "    # Combine train and test to ensure consistent encoding\n",
    "    combined = pd.concat([train_df, test_df])\n",
    "    user_encoder.fit(combined['user_id'])\n",
    "    item_encoder.fit(combined['item_id'])\n",
    "    \n",
    "    # Create various formats of the data for different algorithms\n",
    "    \n",
    "    # 1. Pandas DataFrames with original IDs\n",
    "    train_df = train_df.sort_values(['user_id', 'timestamp'])\n",
    "    test_df = test_df.sort_values(['user_id', 'timestamp'])\n",
    "    \n",
    "    # 2. Pandas DataFrames with encoded IDs\n",
    "    train_df_encoded = train_df.copy()\n",
    "    test_df_encoded = test_df.copy()\n",
    "    \n",
    "    train_df_encoded['user_idx'] = user_encoder.transform(train_df['user_id'])\n",
    "    train_df_encoded['item_idx'] = item_encoder.transform(train_df['item_id'])\n",
    "    test_df_encoded['user_idx'] = user_encoder.transform(test_df['user_id'])\n",
    "    test_df_encoded['item_idx'] = item_encoder.transform(test_df['item_id'])\n",
    "    \n",
    "    # 3. Dictionaries for easier lookups\n",
    "    # User -> items in train\n",
    "    train_user_items = defaultdict(list)\n",
    "    for _, row in train_df.iterrows():\n",
    "        train_user_items[row['user_id']].append((row['item_id'], row['rating']))\n",
    "    \n",
    "    # User -> items in test\n",
    "    test_user_items = defaultdict(list)\n",
    "    for _, row in test_df.iterrows():\n",
    "        test_user_items[row['user_id']].append((row['item_id'], row['rating']))\n",
    "    \n",
    "    # 4. Surprise format\n",
    "    reader = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
    "    train_surprise = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    train_surprise_full = train_surprise.build_full_trainset()\n",
    "    \n",
    "    # Convert test data to Surprise format (list of tuples)\n",
    "    test_surprise = [(row['user_id'], row['item_id'], row['rating']) for _, row in test_df.iterrows()]\n",
    "    \n",
    "    # Return all formats\n",
    "    return {\n",
    "        'train_df': train_df,\n",
    "        'test_df': test_df,\n",
    "        'train_df_encoded': train_df_encoded,\n",
    "        'test_df_encoded': test_df_encoded,\n",
    "        'train_user_items': train_user_items,\n",
    "        'test_user_items': test_user_items,\n",
    "        'train_surprise': train_surprise,\n",
    "        'train_surprise_full': train_surprise_full,\n",
    "        'test_surprise': test_surprise,\n",
    "        'user_encoder': user_encoder,\n",
    "        'item_encoder': item_encoder,\n",
    "        'n_users': len(user_encoder.classes_),\n",
    "        'n_items': len(item_encoder.classes_),\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Recommender Algorithms\n",
    "# =============================================================================\n",
    "\n",
    "class PopularityRecommender:\n",
    "    \"\"\"\n",
    "    Popularity-based recommender system that recommends the most popular items\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.item_popularity = None\n",
    "        self.items = None\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        Fit the recommender model to training data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        train_df : pandas.DataFrame\n",
    "            DataFrame with columns: user_id, item_id, rating\n",
    "        \"\"\"\n",
    "        # Calculate item popularity as the frequency of ratings\n",
    "        self.item_popularity = train_df['item_id'].value_counts().to_dict()\n",
    "        self.items = list(self.item_popularity.keys())\n",
    "        self.items.sort(key=lambda x: self.item_popularity[x], reverse=True)\n",
    "        return self\n",
    "    \n",
    "    def recommend(self, user_id, train_user_items, n=10):\n",
    "        \"\"\"\n",
    "        Recommend items for a user\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int or str\n",
    "            User ID\n",
    "        train_user_items : dict\n",
    "            Dictionary mapping user_id to list of (item_id, rating) tuples of items they've rated\n",
    "        n : int\n",
    "            Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of top n recommended item IDs\n",
    "        \"\"\"\n",
    "        # Get items the user has already rated\n",
    "        rated_items = [item for item, _ in train_user_items.get(user_id, [])]\n",
    "        \n",
    "        # Recommend the most popular items that the user hasn't rated yet\n",
    "        recommendations = []\n",
    "        for item in self.items:\n",
    "            if item not in rated_items:\n",
    "                recommendations.append(item)\n",
    "                if len(recommendations) >= n:\n",
    "                    break\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Predict ratings for given user-item pairs\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_ids : array-like\n",
    "            User IDs\n",
    "        item_ids : array-like\n",
    "            Item IDs\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Predicted ratings\n",
    "        \"\"\"\n",
    "        # For popularity-based, we use the relative popularity as prediction\n",
    "        # Normalize to [0,1] range\n",
    "        max_pop = max(self.item_popularity.values())\n",
    "        \n",
    "        predictions = []\n",
    "        for item in item_ids:\n",
    "            if item in self.item_popularity:\n",
    "                # Scale by max popularity to get a relative score\n",
    "                predictions.append(self.item_popularity[item] / max_pop)\n",
    "            else:\n",
    "                predictions.append(0.0)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "class RandomRecommender:\n",
    "    \"\"\"\n",
    "    Random recommender system that recommends items at random\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        self.items = None\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        Fit the recommender model to training data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        train_df : pandas.DataFrame\n",
    "            DataFrame with columns: user_id, item_id, rating\n",
    "        \"\"\"\n",
    "        # Store the list of all items\n",
    "        self.items = train_df['item_id'].unique()\n",
    "        return self\n",
    "    \n",
    "    def recommend(self, user_id, train_user_items, n=10):\n",
    "        \"\"\"\n",
    "        Recommend items for a user\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int or str\n",
    "            User ID\n",
    "        train_user_items : dict\n",
    "            Dictionary mapping user_id to list of (item_id, rating) tuples of items they've rated\n",
    "        n : int\n",
    "            Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of top n recommended item IDs\n",
    "        \"\"\"\n",
    "        # Get items the user has already rated\n",
    "        rated_items = [item for item, _ in train_user_items.get(user_id, [])]\n",
    "        \n",
    "        # Get candidate items (those not yet rated by the user)\n",
    "        candidate_items = [item for item in self.items if item not in rated_items]\n",
    "        \n",
    "        # If there are no candidates or fewer than requested, return what we have\n",
    "        if len(candidate_items) <= n:\n",
    "            return candidate_items\n",
    "        \n",
    "        # Randomly select n items\n",
    "        return self.rng.choice(candidate_items, size=n, replace=False)\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Predict ratings for given user-item pairs\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_ids : array-like\n",
    "            User IDs\n",
    "        item_ids : array-like\n",
    "            Item IDs\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Predicted ratings\n",
    "        \"\"\"\n",
    "        # For random recommender, we just return random predictions\n",
    "        return self.rng.rand(len(user_ids))\n",
    "\n",
    "class MatrixFactorizationRecommender:\n",
    "    \"\"\"\n",
    "    Matrix Factorization recommender using Surprise's SVD algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=None):\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr_all = lr_all\n",
    "        self.reg_all = reg_all\n",
    "        self.random_state = random_state\n",
    "        self.model = SVD(\n",
    "            n_factors=n_factors,\n",
    "            n_epochs=n_epochs,\n",
    "            lr_all=lr_all,\n",
    "            reg_all=reg_all,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        \"\"\"\n",
    "        Fit the recommender model to training data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        trainset : surprise.Trainset\n",
    "            Surprise Trainset object\n",
    "        \"\"\"\n",
    "        self.model.fit(trainset)\n",
    "        return self\n",
    "    \n",
    "    def recommend(self, user_id, train_user_items, n=10):\n",
    "        \"\"\"\n",
    "        Recommend items for a user\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int or str\n",
    "            User ID\n",
    "        train_user_items : dict\n",
    "            Dictionary mapping user_id to list of (item_id, rating) tuples of items they've rated\n",
    "        n : int\n",
    "            Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of top n recommended item IDs\n",
    "        \"\"\"\n",
    "        # Get items the user has already rated\n",
    "        rated_items = [item for item, _ in train_user_items.get(user_id, [])]\n",
    "        \n",
    "        # Get all items from the model\n",
    "        all_items = set(self.model.trainset._raw2inner_id_items.keys())\n",
    "        \n",
    "        # Get candidate items (those not yet rated by the user)\n",
    "        candidate_items = [item for item in all_items if item not in rated_items]\n",
    "        \n",
    "        # Calculate predictions for all candidate items\n",
    "        predictions = [(item, self.model.predict(user_id, item).est) for item in candidate_items]\n",
    "        \n",
    "        # Sort by predicted rating\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top n items\n",
    "        return [item for item, _ in predictions[:n]]\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Predict ratings for given user-item pairs\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_ids : array-like\n",
    "            User IDs\n",
    "        item_ids : array-like\n",
    "            Item IDs\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Predicted ratings\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for user, item in zip(user_ids, item_ids):\n",
    "            try:\n",
    "                pred = self.model.predict(user, item).est\n",
    "                predictions.append(pred)\n",
    "            except Exception:\n",
    "                # If user or item is unknown, predict the global mean\n",
    "                predictions.append(self.model.trainset.global_mean)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "class ItemKNNRecommender:\n",
    "    \"\"\"\n",
    "    Item-based K-Nearest Neighbors recommender using Surprise\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=20, min_k=1, sim_options=None, random_state=None):\n",
    "        if sim_options is None:\n",
    "            # Default similarity options\n",
    "            sim_options = {\n",
    "                'name': 'cosine',\n",
    "                'user_based': False  # Item-based similarity\n",
    "            }\n",
    "        \n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "        self.sim_options = sim_options\n",
    "        self.random_state = random_state\n",
    "        self.model = KNNBasic(\n",
    "            k=k,\n",
    "            min_k=min_k,\n",
    "            sim_options=sim_options,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        \"\"\"\n",
    "        Fit the recommender model to training data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        trainset : surprise.Trainset\n",
    "            Surprise Trainset object\n",
    "        \"\"\"\n",
    "        self.model.fit(trainset)\n",
    "        return self\n",
    "    \n",
    "    def recommend(self, user_id, train_user_items, n=10):\n",
    "        \"\"\"\n",
    "        Recommend items for a user\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int or str\n",
    "            User ID\n",
    "        train_user_items : dict\n",
    "            Dictionary mapping user_id to list of (item_id, rating) tuples of items they've rated\n",
    "        n : int\n",
    "            Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of top n recommended item IDs\n",
    "        \"\"\"\n",
    "        # Get items the user has already rated\n",
    "        rated_items = [item for item, _ in train_user_items.get(user_id, [])]\n",
    "        \n",
    "        # Get all items from the model\n",
    "        all_items = set(self.model.trainset._raw2inner_id_items.keys())\n",
    "        \n",
    "        # Get candidate items (those not yet rated by the user)\n",
    "        candidate_items = [item for item in all_items if item not in rated_items]\n",
    "        \n",
    "        # Calculate predictions for all candidate items\n",
    "        predictions = [(item, self.model.predict(user_id, item).est) for item in candidate_items]\n",
    "        \n",
    "        # Sort by predicted rating\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top n items\n",
    "        return [item for item, _ in predictions[:n]]\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Predict ratings for given user-item pairs\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_ids : array-like\n",
    "            User IDs\n",
    "        item_ids : array-like\n",
    "            Item IDs\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Predicted ratings\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for user, item in zip(user_ids, item_ids):\n",
    "            try:\n",
    "                pred = self.model.predict(user, item).est\n",
    "                predictions.append(pred)\n",
    "            except Exception:\n",
    "                # If user or item is unknown, predict the global mean\n",
    "                predictions.append(self.model.trainset.global_mean)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "# =============================================================================\n",
    "# Evaluation Metrics\n",
    "# =============================================================================\n",
    "\n",
    "# Rating Prediction Metrics\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Square Error\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Actual ratings\n",
    "    y_pred : array-like\n",
    "        Predicted ratings\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        RMSE value\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Mean Absolute Error\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Actual ratings\n",
    "    y_pred : array-like\n",
    "        Predicted ratings\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        MAE value\n",
    "    \"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Ranking Metrics\n",
    "\n",
    "def precision_at_k(recommended_items, relevant_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Precision@k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommended_items : list\n",
    "        List of recommended item IDs, ordered by relevance\n",
    "    relevant_items : list or set\n",
    "        Set of item IDs that are actually relevant\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Precision@k value\n",
    "    \"\"\"\n",
    "    if len(recommended_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Ensure k doesn't exceed the length of recommended items\n",
    "    k = min(k, len(recommended_items))\n",
    "    recommended_k = recommended_items[:k]\n",
    "    \n",
    "    # Convert relevant_items to set for O(1) lookups\n",
    "    relevant_items_set = set(relevant_items)\n",
    "    \n",
    "    # Count relevant items in top-k recommendations\n",
    "    relevant_and_recommended = sum(1 for item in recommended_k if item in relevant_items_set)\n",
    "    \n",
    "    return relevant_and_recommended / k\n",
    "\n",
    "def recall_at_k(recommended_items, relevant_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Recall@k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommended_items : list\n",
    "        List of recommended item IDs, ordered by relevance\n",
    "    relevant_items : list or set\n",
    "        Set of item IDs that are actually relevant\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Recall@k value\n",
    "    \"\"\"\n",
    "    if len(relevant_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Ensure k doesn't exceed the length of recommended items\n",
    "    k = min(k, len(recommended_items))\n",
    "    recommended_k = recommended_items[:k]\n",
    "    \n",
    "    # Convert relevant_items to set for O(1) lookups\n",
    "    relevant_items_set = set(relevant_items)\n",
    "    \n",
    "    # Count relevant items in top-k recommendations\n",
    "    relevant_and_recommended = sum(1 for item in recommended_k if item in relevant_items_set)\n",
    "    \n",
    "    return relevant_and_recommended / len(relevant_items)\n",
    "\n",
    "def f1_at_k(recommended_items, relevant_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculate F1-score@k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommended_items : list\n",
    "        List of recommended item IDs, ordered by relevance\n",
    "    relevant_items : list or set\n",
    "        Set of item IDs that are actually relevant\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        F1-score@k value\n",
    "    \"\"\"\n",
    "    p = precision_at_k(recommended_items, relevant_items, k)\n",
    "    r = recall_at_k(recommended_items, relevant_items, k)\n",
    "    \n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return 2 * (p * r) / (p + r)\n",
    "\n",
    "def average_precision_at_k(recommended_items, relevant_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Average Precision at k for a single user\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommended_items : list\n",
    "        List of recommended item IDs, ordered by relevance\n",
    "    relevant_items : list or set\n",
    "        Set of item IDs that are actually relevant\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Average Precision@k value\n",
    "    \"\"\"\n",
    "    if not relevant_items:\n",
    "        return 0.0\n",
    "    \n",
    "    # Ensure k doesn't exceed the length of recommended items\n",
    "    k = min(k, len(recommended_items))\n",
    "    recommended_k = recommended_items[:k]\n",
    "    \n",
    "    # Convert relevant_items to set for O(1) lookups\n",
    "    relevant_items_set = set(relevant_items)\n",
    "    \n",
    "    hits = 0\n",
    "    sum_precisions = 0\n",
    "    \n",
    "    for i, item in enumerate(recommended_k):\n",
    "        if item in relevant_items_set:\n",
    "            hits += 1\n",
    "            # Precision at current hit position\n",
    "            precision_at_i = hits / (i + 1)\n",
    "            sum_precisions += precision_at_i\n",
    "    \n",
    "    return sum_precisions / min(len(relevant_items_set), k)\n",
    "\n",
    "def mean_average_precision(recommendations_by_user, relevant_items_by_user, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision at k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    relevant_items_by_user : dict\n",
    "        Dictionary mapping user IDs to their set of relevant items\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        MAP@k value\n",
    "    \"\"\"\n",
    "    aps = []\n",
    "    \n",
    "    for user, recommendations in recommendations_by_user.items():\n",
    "        if user in relevant_items_by_user:\n",
    "            relevant_items = [item for item, _ in relevant_items_by_user[user]]\n",
    "            if relevant_items:  # Only consider users with at least one relevant item\n",
    "                ap = average_precision_at_k(recommendations, relevant_items, k)\n",
    "                aps.append(ap)\n",
    "    \n",
    "    return np.mean(aps) if aps else 0\n",
    "\n",
    "def ndcg_at_k(recommended_items, relevant_items_with_ratings, k=10):\n",
    "    \"\"\"\n",
    "    Calculate normalized Discounted Cumulative Gain (nDCG) at k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommended_items : list\n",
    "        List of recommended item IDs, ordered by predicted relevance\n",
    "    relevant_items_with_ratings : list of tuples\n",
    "        List of (item_id, rating) tuples representing relevant items and their ratings\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        nDCG@k value\n",
    "    \"\"\"\n",
    "    if not relevant_items_with_ratings:\n",
    "        return 0.0\n",
    "    \n",
    "    # Ensure k doesn't exceed the length of recommended items\n",
    "    k = min(k, len(recommended_items))\n",
    "    \n",
    "    # Create a dictionary mapping item_id to rating\n",
    "    relevance_scores = {item: rating for item, rating in relevant_items_with_ratings}\n",
    "    \n",
    "    # Get relevance scores for recommended items (0 if not in relevant items)\n",
    "    recommended_relevances = [relevance_scores.get(item, 0) for item in recommended_items[:k]]\n",
    "    \n",
    "    # Calculate DCG\n",
    "    dcg = 0\n",
    "    for i, rel in enumerate(recommended_relevances):\n",
    "        dcg += (2 ** rel - 1) / np.log2(i + 2)  # i+2 because i is 0-indexed\n",
    "    \n",
    "    # Calculate ideal DCG (for normalization)\n",
    "    # Sort relevant items by their ratings in descending order\n",
    "    sorted_relevances = sorted([rating for _, rating in relevant_items_with_ratings], reverse=True)[:k]\n",
    "    idcg = 0\n",
    "    for i, rel in enumerate(sorted_relevances):\n",
    "        idcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    # Normalize\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return dcg / idcg\n",
    "\n",
    "def mean_ndcg(recommendations_by_user, relevant_items_by_user, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Mean nDCG at k across all users\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    relevant_items_by_user : dict\n",
    "        Dictionary mapping user IDs to their list of (item_id, rating) tuples\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Mean nDCG@k value\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for user, recommendations in recommendations_by_user.items():\n",
    "        if user in relevant_items_by_user:\n",
    "            relevant_items = relevant_items_by_user[user]\n",
    "            if relevant_items:  # Only consider users with at least one relevant item\n",
    "                ndcg = ndcg_at_k(recommendations, relevant_items, k)\n",
    "                ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "def hit_rate_at_k(recommendations_by_user, relevant_items_by_user, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Hit Rate at k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    relevant_items_by_user : dict\n",
    "        Dictionary mapping user IDs to their set of relevant items\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Hit Rate@k value\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    total_users = 0\n",
    "    \n",
    "    for user, recommendations in recommendations_by_user.items():\n",
    "        if user not in relevant_items_by_user:\n",
    "            continue\n",
    "            \n",
    "        total_users += 1\n",
    "        relevant_items = [item for item, _ in relevant_items_by_user[user]]\n",
    "        top_k = recommendations[:k]\n",
    "        \n",
    "        if any(item in relevant_items for item in top_k):\n",
    "            hits += 1\n",
    "    \n",
    "    return hits / total_users if total_users > 0 else 0\n",
    "\n",
    "# Beyond-Accuracy Metrics\n",
    "\n",
    "def catalog_coverage_at_k(recommendations_by_user, total_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Catalog Coverage at k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    total_items : int or set\n",
    "        Total number of items or set of all item IDs\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Catalog Coverage@k value\n",
    "    \"\"\"\n",
    "    all_recommended = set()\n",
    "    \n",
    "    for user, recommendations in recommendations_by_user.items():\n",
    "        all_recommended.update(recommendations[:k])\n",
    "    \n",
    "    if isinstance(total_items, int):\n",
    "        return len(all_recommended) / total_items\n",
    "    else:\n",
    "        return len(all_recommended) / len(total_items)\n",
    "\n",
    "def diversity_at_k(recommendations_by_user, item_features, k=10):\n",
    "    \"\"\"\n",
    "    Calculate average intra-list diversity at k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    item_features : dict\n",
    "        Dictionary mapping item IDs to their feature vectors\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Average diversity at k\n",
    "    \"\"\"\n",
    "    diversity_scores = []\n",
    "    \n",
    "    for user, recommendations in recommendations_by_user.items():\n",
    "        top_k = recommendations[:k]\n",
    "        \n",
    "        if len(top_k) <= 1:\n",
    "            continue\n",
    "            \n",
    "        # Calculate pairwise distances\n",
    "        distances = []\n",
    "        for i in range(len(top_k)):\n",
    "            item_i = top_k[i]\n",
    "            if item_i not in item_features:\n",
    "                continue\n",
    "                \n",
    "            for j in range(i+1, len(top_k)):\n",
    "                item_j = top_k[j]\n",
    "                if item_j not in item_features:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate cosine distance\n",
    "                try:\n",
    "                    dist = cosine(item_features[item_i], item_features[item_j])\n",
    "                    distances.append(dist)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if distances:\n",
    "            diversity_scores.append(np.mean(distances))\n",
    "    \n",
    "    return np.mean(diversity_scores) if diversity_scores else 0\n",
    "\n",
    "def novelty_at_k(recommendations_by_user, item_popularity, total_users, k=10):\n",
    "    \"\"\"\n",
    "    Calculate average Novelty at k\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    item_popularity : dict\n",
    "        Dictionary mapping item IDs to their popularity (number of ratings)\n",
    "    total_users : int\n",
    "        Total number of users in the system\n",
    "    k : int\n",
    "        Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Average novelty at k\n",
    "    \"\"\"\n",
    "    novelty_scores = []\n",
    "    \n",
    "    for user, recommendations in recommendations_by_user.items():\n",
    "        top_k = recommendations[:k]\n",
    "        \n",
    "        if not top_k:\n",
    "            continue\n",
    "            \n",
    "        # Calculate self-information (novelty) for each item\n",
    "        item_novelties = []\n",
    "        for item in top_k:\n",
    "            if item in item_popularity:\n",
    "                # Calculate self-information: -log2(popularity)\n",
    "                pop = item_popularity[item] / total_users\n",
    "                novelty = -np.log2(pop) if pop > 0 else 0\n",
    "                item_novelties.append(novelty)\n",
    "        \n",
    "        if item_novelties:\n",
    "            # Average novelty for this user's recommendations\n",
    "            novelty_scores.append(np.mean(item_novelties))\n",
    "    \n",
    "    return np.mean(novelty_scores) if novelty_scores else 0\n",
    "\n",
    "def evaluate_recommendations(recommendations_by_user, relevant_items_by_user, item_features=None, \n",
    "                           item_popularity=None, total_users=None, total_items=None, k_values=None):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of recommendations\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    recommendations_by_user : dict\n",
    "        Dictionary mapping user IDs to their ordered list of recommended items\n",
    "    relevant_items_by_user : dict\n",
    "        Dictionary mapping user IDs to their list of (item_id, rating) tuples\n",
    "    item_features : dict, optional\n",
    "        Dictionary mapping item IDs to their feature vectors (for diversity)\n",
    "    item_popularity : dict, optional\n",
    "        Dictionary mapping item IDs to their popularity (for novelty)\n",
    "    total_users : int, optional\n",
    "        Total number of users (for novelty)\n",
    "    total_items : int or set, optional\n",
    "        Total number of items or set of all item IDs (for coverage)\n",
    "    k_values : list, optional\n",
    "        List of k values to evaluate at (default: [5, 10, 20])\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    if k_values is None:\n",
    "        k_values = [5, 10, 20]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # For each k value\n",
    "    for k in k_values:\n",
    "        k_results = {}\n",
    "        \n",
    "        # Precision, Recall, F1\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for user, recommendations in recommendations_by_user.items():\n",
    "            if user in relevant_items_by_user:\n",
    "                relevant_items = [item for item, _ in relevant_items_by_user[user]]\n",
    "                if relevant_items:\n",
    "                    p = precision_at_k(recommendations, relevant_items, k)\n",
    "                    r = recall_at_k(recommendations, relevant_items, k)\n",
    "                    f1 = f1_at_k(recommendations, relevant_items, k)\n",
    "                    \n",
    "                    precisions.append(p)\n",
    "                    recalls.append(r)\n",
    "                    f1_scores.append(f1)\n",
    "        \n",
    "        k_results['precision'] = np.mean(precisions) if precisions else 0\n",
    "        k_results['recall'] = np.mean(recalls) if recalls else 0\n",
    "        k_results['f1'] = np.mean(f1_scores) if f1_scores else 0\n",
    "        \n",
    "        # MAP\n",
    "        k_results['map'] = mean_average_precision(recommendations_by_user, relevant_items_by_user, k)\n",
    "        \n",
    "        # nDCG\n",
    "        k_results['ndcg'] = mean_ndcg(recommendations_by_user, relevant_items_by_user, k)\n",
    "        \n",
    "        # Hit Rate\n",
    "        k_results['hit_rate'] = hit_rate_at_k(recommendations_by_user, relevant_items_by_user, k)\n",
    "        \n",
    "        # Catalog Coverage\n",
    "        if total_items is not None:\n",
    "            k_results['coverage'] = catalog_coverage_at_k(recommendations_by_user, total_items, k)\n",
    "        \n",
    "        # Diversity\n",
    "        if item_features is not None:\n",
    "            k_results['diversity'] = diversity_at_k(recommendations_by_user, item_features, k)\n",
    "        \n",
    "        # Novelty\n",
    "        if item_popularity is not None and total_users is not None:\n",
    "            k_results['novelty'] = novelty_at_k(recommendations_by_user, item_popularity, total_users, k)\n",
    "        \n",
    "        results[k] = k_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_rating_prediction(model, testset, format_type='surprise'):\n",
    "    \"\"\"\n",
    "    Evaluate rating prediction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : object\n",
    "        Recommender system model with predict method\n",
    "    testset : list or pandas.DataFrame\n",
    "        Test set in specified format\n",
    "    format_type : str\n",
    "        Format of test set ('surprise', 'dataframe')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    if format_type == 'surprise':\n",
    "        # Surprise format: list of (user_id, item_id, rating) tuples\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for uid, iid, true_rating in testset:\n",
    "            pred_rating = model.model.predict(uid, iid).est\n",
    "            y_true.append(true_rating)\n",
    "            y_pred.append(pred_rating)\n",
    "    \n",
    "    elif format_type == 'dataframe':\n",
    "        # DataFrame format\n",
    "        y_true = testset['rating'].values\n",
    "        y_pred = model.predict(testset['user_id'].values, testset['item_id'].values)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown format type: {format_type}\")\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse(y_true, y_pred),\n",
    "        'mae': mae(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def run_experiment(models, dataset, k_values=None, implicit=False, threshold=None):\n",
    "    \"\"\"\n",
    "    Run a comprehensive experiment with multiple models and evaluation metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : list of tuples\n",
    "        List of (name, model) tuples\n",
    "    dataset : dict\n",
    "        Dataset from prepare_dataset function\n",
    "    k_values : list, optional\n",
    "        List of k values to evaluate at (default: [5, 10, 20])\n",
    "    implicit : bool\n",
    "        Whether the data should be treated as implicit feedback\n",
    "    threshold : float, optional\n",
    "        Threshold for implicit conversion\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of results\n",
    "    \"\"\"\n",
    "    if k_values is None:\n",
    "        k_values = [5, 10, 20]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Compute item popularity (for novelty calculation)\n",
    "    item_popularity = dataset['train_df']['item_id'].value_counts().to_dict()\n",
    "    total_users = len(dataset['train_df']['user_id'].unique())\n",
    "    total_items = len(dataset['train_df']['item_id'].unique())\n",
    "    \n",
    "    # If the data is explicit, use ratings as is\n",
    "    # If implicit, convert test ratings to binary based on threshold\n",
    "    if implicit:\n",
    "        if threshold is None:\n",
    "            threshold = dataset['test_df']['rating'].median()\n",
    "        \n",
    "        # Convert test ratings to binary\n",
    "        for user in dataset['test_user_items']:\n",
    "            dataset['test_user_items'][user] = [\n",
    "                (item, 1.0 if rating >= threshold else 0.0)\n",
    "                for item, rating in dataset['test_user_items'][user]\n",
    "            ]\n",
    "    \n",
    "    # For each model\n",
    "    for model_name, model in models:\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        model_results = {'name': model_name}\n",
    "        \n",
    "        # Generate recommendations for all users\n",
    "        recommendations = {}\n",
    "        \n",
    "        # Get all users to evaluate (those with items in test set)\n",
    "        test_users = list(dataset['test_user_items'].keys())\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Generate recommendations for each user\n",
    "        for user in test_users:\n",
    "            try:\n",
    "                recs = model.recommend(user, dataset['train_user_items'], n=max(k_values))\n",
    "                recommendations[user] = recs\n",
    "            except Exception as e:\n",
    "                print(f\"  Error generating recommendations for user {user}: {e}\")\n",
    "        \n",
    "        recommend_time = time.time() - start_time\n",
    "        model_results['recommend_time'] = recommend_time\n",
    "        print(f\"  Generated recommendations in {recommend_time:.2f} seconds\")\n",
    "        \n",
    "        # Evaluate recommendations\n",
    "        start_time = time.time()\n",
    "        model_results['ranking'] = evaluate_recommendations(\n",
    "            recommendations,\n",
    "            dataset['test_user_items'],\n",
    "            item_popularity=item_popularity,\n",
    "            total_users=total_users,\n",
    "            total_items=total_items,\n",
    "            k_values=k_values\n",
    "        )\n",
    "        \n",
    "        evaluate_time = time.time() - start_time\n",
    "        model_results['evaluate_time'] = evaluate_time\n",
    "        print(f\"  Evaluated recommendations in {evaluate_time:.2f} seconds\")\n",
    "        \n",
    "        # Add to results\n",
    "        results[model_name] = model_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# Visualization Functions\n",
    "# =============================================================================\n",
    "\n",
    "def plot_metric_by_k(results, metric, k_values=None, title=None, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot a specific metric for different models across k values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from run_experiment\n",
    "    metric : str\n",
    "        Metric to plot\n",
    "    k_values : list, optional\n",
    "        List of k values to include\n",
    "    title : str, optional\n",
    "        Plot title\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    if k_values is None:\n",
    "        # Get k values from the first model's results\n",
    "        first_model = next(iter(results.values()))\n",
    "        k_values = sorted(first_model['ranking'].keys())\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        values = [model_results['ranking'][k].get(metric, 0) for k in k_values]\n",
    "        plt.plot(k_values, values, marker='o', label=model_name)\n",
    "    \n",
    "    plt.xlabel('k (Number of recommendations)')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f'{metric.capitalize()} by k')\n",
    "        \n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics_comparison(results, k=10, metrics=None, title=None, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Plot a bar chart comparing different metrics across models\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from run_experiment\n",
    "    k : int\n",
    "        K value to use for comparison\n",
    "    metrics : list, optional\n",
    "        List of metrics to include\n",
    "    title : str, optional\n",
    "        Plot title\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        # Get metrics from the first model's results\n",
    "        first_model = next(iter(results.values()))\n",
    "        metrics = list(first_model['ranking'][k].keys())\n",
    "    \n",
    "    # Create a DataFrame for the comparison\n",
    "    data = []\n",
    "    model_names = []\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        model_names.append(model_name)\n",
    "        data.append([model_results['ranking'][k].get(metric, 0) for metric in metrics])\n",
    "    \n",
    "    df = pd.DataFrame(data, index=model_names, columns=metrics)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    df.plot(kind='bar', figsize=figsize)\n",
    "    \n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Value')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f'Metrics Comparison (k={k})')\n",
    "        \n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(title='Metric')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_radar_chart(results, k=10, metrics=None, title=None, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Create a radar chart to compare models across multiple metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from run_experiment\n",
    "    k : int\n",
    "        K value to use for comparison\n",
    "    metrics : list, optional\n",
    "        List of metrics to include\n",
    "    title : str, optional\n",
    "        Plot title\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        # Get metrics from the first model's results\n",
    "        first_model = next(iter(results.values()))\n",
    "        metrics = list(first_model['ranking'][k].keys())\n",
    "    \n",
    "    # Normalize metrics to [0,1] for fair comparison\n",
    "    max_values = {}\n",
    "    for metric in metrics:\n",
    "        all_values = [model_results['ranking'][k].get(metric, 0) for model_results in results.values()]\n",
    "        max_values[metric] = max(all_values) if all_values else 1\n",
    "    \n",
    "    # Number of metrics\n",
    "    N = len(metrics)\n",
    "    \n",
    "    # Compute angles for each metric\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the polygon\n",
    "    \n",
    "    # Initialize figure\n",
    "    fig, ax = plt.subplots(figsize=figsize, subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # Plot each model\n",
    "    for i, (model_name, model_results) in enumerate(results.items()):\n",
    "        values = []\n",
    "        for metric in metrics:\n",
    "            value = model_results['ranking'][k].get(metric, 0)\n",
    "            # Normalize\n",
    "            if max_values[metric] > 0:\n",
    "                value = value / max_values[metric]\n",
    "            values.append(value)\n",
    "        \n",
    "        values += values[:1]  # Close the polygon\n",
    "        \n",
    "        # Plot\n",
    "        ax.plot(angles, values, linewidth=2, label=model_name)\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics)\n",
    "    \n",
    "    # Add legend and title\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f'Model Comparison (k={k})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics_heatmap(results, k=10, metrics=None, title=None, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Create a heatmap to compare models across multiple metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from run_experiment\n",
    "    k : int\n",
    "        K value to use for comparison\n",
    "    metrics : list, optional\n",
    "        List of metrics to include\n",
    "    title : str, optional\n",
    "        Plot title\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        # Get metrics from the first model's results\n",
    "        first_model = next(iter(results.values()))\n",
    "        metrics = list(first_model['ranking'][k].keys())\n",
    "    \n",
    "    # Create a DataFrame for the heatmap\n",
    "    data = []\n",
    "    model_names = []\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        model_names.append(model_name)\n",
    "        data.append([model_results['ranking'][k].get(metric, 0) for metric in metrics])\n",
    "    \n",
    "    df = pd.DataFrame(data, index=model_names, columns=metrics)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(df, annot=True, cmap='viridis', fmt='.3f', linewidths=.5)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f'Metrics Comparison Heatmap (k={k})')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_summary(results, k=10, metrics=None):\n",
    "    \"\"\"\n",
    "    Create multiple visualizations of results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from run_experiment\n",
    "    k : int\n",
    "        K value to use for comparison\n",
    "    metrics : list, optional\n",
    "        List of metrics to include\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        # Get metrics from the first model's results\n",
    "        first_model = next(iter(results.values()))\n",
    "        metrics = list(first_model['ranking'][k].keys())\n",
    "    \n",
    "    # Plot individual metrics by k\n",
    "    for metric in metrics:\n",
    "        plot_metric_by_k(results, metric, title=f'{metric.capitalize()} by k')\n",
    "    \n",
    "    # Plot metrics comparison\n",
    "    plot_metrics_comparison(results, k, metrics)\n",
    "    \n",
    "    # Plot radar chart\n",
    "    plot_radar_chart(results, k, metrics)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plot_metrics_heatmap(results, k, metrics)\n",
    "\n",
    "# =============================================================================\n",
    "# Main Function\n",
    "# =============================================================================\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Main function to run the script\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    args : argparse.Namespace\n",
    "        Command line arguments\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Recommender System Evaluation - Dataset: {args.dataset}, Size: {args.size}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    if not os.path.exists(args.data_dir):\n",
    "        os.makedirs(args.data_dir)\n",
    "    \n",
    "    # Download dataset\n",
    "    if args.dataset == 'movielens':\n",
    "        ratings, items = download_movielens(args.size, args.data_dir)\n",
    "    elif args.dataset == 'lastfm':\n",
    "        ratings, items = download_lastfm(args.data_dir)\n",
    "    elif args.dataset == 'amazon':\n",
    "        ratings, items = download_amazon_reviews(args.size, args.data_dir)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {args.dataset}\")\n",
    "    \n",
    "    if ratings is None:\n",
    "        print(\"Failed to load dataset. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Prepare dataset (implicit or explicit)\n",
    "    dataset = prepare_dataset(ratings, args.test_size, args.implicit, args.threshold)\n",
    "    \n",
    "    # Create item features dict if items dataframe is available\n",
    "    item_features = None\n",
    "    if items is not None and 'genres' in items.columns:\n",
    "        # For MovieLens, use genres as features\n",
    "        # Create one-hot encoding of genres\n",
    "        genres = set()\n",
    "        for genre_list in items['genres']:\n",
    "            for genre in genre_list.split('|'):\n",
    "                genres.add(genre)\n",
    "        \n",
    "        item_features = {}\n",
    "        for _, row in items.iterrows():\n",
    "            item_id = row['item_id']\n",
    "            genre_list = row['genres'].split('|')\n",
    "            # Create binary vector\n",
    "            feature_vector = np.zeros(len(genres))\n",
    "            for i, genre in enumerate(sorted(genres)):\n",
    "                if genre in genre_list:\n",
    "                    feature_vector[i] = 1\n",
    "            item_features[item_id] = feature_vector\n",
    "    \n",
    "    # Initialize models\n",
    "    models = []\n",
    "    \n",
    "    # Add requested models\n",
    "    if 'popularity' in args.models:\n",
    "        popularity_model = PopularityRecommender()\n",
    "        popularity_model.fit(dataset['train_df'])\n",
    "        models.append(('Popularity', popularity_model))\n",
    "    \n",
    "    if 'random' in args.models:\n",
    "        random_model = RandomRecommender(random_state=42)\n",
    "        random_model.fit(dataset['train_df'])\n",
    "        models.append(('Random', random_model))\n",
    "    \n",
    "    if 'mf' in args.models:\n",
    "        mf_model = MatrixFactorizationRecommender(\n",
    "            n_factors=args.factors,\n",
    "            n_epochs=args.epochs,\n",
    "            random_state=42\n",
    "        )\n",
    "        mf_model.fit(dataset['train_surprise_full'])\n",
    "        models.append(('MatrixFactorization', mf_model))\n",
    "    \n",
    "    if 'itemknn' in args.models:\n",
    "        knn_model = ItemKNNRecommender(\n",
    "            k=args.neighbors,\n",
    "            random_state=42\n",
    "        )\n",
    "        knn_model.fit(dataset['train_surprise_full'])\n",
    "        models.append(('ItemKNN', knn_model))\n",
    "    \n",
    "    # Run experiment\n",
    "    results = run_experiment(\n",
    "        models,\n",
    "        dataset,\n",
    "        k_values=args.k_values,\n",
    "        implicit=args.implicit,\n",
    "        threshold=args.threshold\n",
    "    )\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results_summary(results, k=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Recommender System Evaluation Script')\n",
    "    \n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--dataset', type=str, default='movielens',\n",
    "                       choices=['movielens', 'lastfm', 'amazon'],\n",
    "                       help='Dataset to use')\n",
    "    parser.add_argument('--size', type=str, default='100k',\n",
    "                       help='Size/variant of the dataset')\n",
    "    parser.add_argument('--data_dir', type=str, default='data',\n",
    "                       help='Directory to store datasets')\n",
    "    \n",
    "    # Experiment parameters\n",
    "    parser.add_argument('--models', nargs='+', default=['popularity', 'random', 'mf', 'itemknn'],\n",
    "                       choices=['popularity', 'random', 'mf', 'itemknn'],\n",
    "                       help='Models to evaluate')\n",
    "    parser.add_argument('--k_values', nargs='+', type=int, default=[5, 10, 20],\n",
    "                       help='K values for evaluation')\n",
    "    parser.add_argument('--test_size', type=float, default=0.2,\n",
    "                       help='Proportion of data to use for testing')\n",
    "    parser.add_argument('--implicit', action='store_true',\n",
    "                       help='Treat as implicit feedback data')\n",
    "    parser.add_argument('--threshold', type=float, default=None,\n",
    "                       help='Threshold for implicit conversion')\n",
    "    \n",
    "    # Model parameters\n",
    "    parser.add_argument('--factors', type=int, default=100,\n",
    "                       help='Number of factors for matrix factorization')\n",
    "    parser.add_argument('--epochs', type=int, default=20,\n",
    "                       help='Number of epochs for training')\n",
    "    parser.add_argument('--neighbors', type=int, default=20,\n",
    "                       help='Number of neighbors for KNN')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
